
@article{ansley_note_1986,
	title = {A note on reparameterizing a vector autoregressive moving average model to enforce stationarity},
	volume = {24},
	issn = {0094-9655},
	url = {http://dx.doi.org/10.1080/00949658608810893},
	doi = {10.1080/00949658608810893},
	abstract = {We use the orrespondence between the partial autocorrelation matrices and the parameter matrices of a vector autoregression to obtain a new parameterization of a vector ARMA model that enforces the stationarity condition. We show how to go efficiently from the new parameterization ohe usual one. Thus the likelihood of observations from an ARMA model can easily be obtained using the new parameterization. In addition, for vector autoregressive models and scalar ARMA models, the new parameterization permits fast computation of the autocovariances of the model.},
	number = {2},
	urldate = {2014-10-13},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Ansley, Craig F. and Kohn, Robert},
	month = jun,
	year = {1986},
	note = {00025},
	pages = {99--106},
	file = {Ansley and Kohn - 1986 - A note on reparameterizing a vector autoregressive.pdf:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/SWQJMPG9/Ansley and Kohn - 1986 - A note on reparameterizing a vector autoregressive.pdf:application/pdf;Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/GQ4WCK2M/00949658608810893.html:text/html}
}

@article{koopman_fast_2000,
	title = {Fast {Filtering} and {Smoothing} for {Multivariate} {State} {Space} {Models}},
	volume = {21},
	copyright = {Blackwell Publishers Ltd 2000},
	issn = {1467-9892},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9892.00186/abstract},
	doi = {10.1111/1467-9892.00186},
	abstract = {This paper investigates a new approach to diffuse filtering and smoothing for multivariate state space models. The standard approach treats the observations as vectors, while our approach treats each element of the observational vector individually. This strategy leads to computationally efficient methods for multivariate filtering and smoothing. Also, the treatment of the diffuse initial state vector in multivariate models is much simpler than in existing methods. The paper presents details of relevant algorithms for filtering, prediction and smoothing. Proofs are provided. Three examples of multivariate models in statistics and economics are presented for which the new approach is particularly relevant.},
	language = {en},
	number = {3},
	urldate = {2014-10-28},
	journal = {Journal of Time Series Analysis},
	author = {Koopman, S. J. and Durbin, J.},
	month = may,
	year = {2000},
	note = {00101},
	pages = {281--296},
	file = {Koopman and Durbin - 2000 - Fast Filtering and Smoothing for Multivariate Stat.pdf:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/N67VU78E/Koopman and Durbin - 2000 - Fast Filtering and Smoothing for Multivariate Stat.pdf:application/pdf;Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/ME3EABZ9/abstract.html:text/html}
}

@techreport{kim_state-space_1999,
	type = {{MIT} {Press} {Books}},
	title = {State-{Space} {Models} with {Regime} {Switching}: {Classical} and {Gibbs}-{Sampling} {Approaches} with {Applications}},
	shorttitle = {State-{Space} {Models} with {Regime} {Switching}},
	url = {http://ideas.repec.org/b/mtp/titles/0262112388.html},
	abstract = {Both state-space models and Markov switching models have been highly productive paths for empirical research in macroeconomics and finance. This book presents recent advances in econometric methods that make feasible the estimation of models that have both features. One approach, in the classical framework, approximates the likelihood function; the other, in the Bayesian framework, uses Gibbs-sampling to simulate posterior distributions from data. The authors present numerous applications of these approaches in detail: decomposition of time series into trend and cycle, a new index of coincident economic indicators, approaches to modeling monetary policy uncertainty, Friedman's "plucking" model of recessions, the detection of turning points in the business cycle and the question of whether booms and recessions are duration-dependent, state-space models with heteroskedastic disturbances, fads and crashes in financial markets, long-run real exchange rates, and mean reversion in asset returns.},
	urldate = {2013-05-03},
	institution = {The MIT Press},
	author = {Kim, Chang-Jin and Nelson, Charles R.},
	year = {1999},
	file = {RePEc Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/RZ8URJE9/0262112388.html:text/html}
}

@article{chib_understanding_1995,
	title = {Understanding the {Metropolis}-{Hastings} {Algorithm}},
	volume = {49},
	copyright = {Copyright © 1995 American Statistical Association},
	issn = {0003-1305},
	url = {http://www.jstor.org/stable/2684568},
	doi = {10.2307/2684568},
	abstract = {We provide a detailed, introductory exposition of the Metropolis-Hastings algorithm, a powerful Markov chain method to simulate multivariate distributions. A simple, intuitive derivation of this method is given along with guidance on implementation. Also discussed are two applications of the algorithm, one for implementing acceptance-rejection sampling when a blanketing function is not available and the other for implementing the algorithm with block-at-a-time scans. In the latter situation, many different algorithms, including the Gibbs sampler, are shown to be special cases of the Metropolis-Hastings algorithm. The methods are illustrated with examples.},
	number = {4},
	urldate = {2013-06-05},
	journal = {The American Statistician},
	author = {Chib, Siddhartha and Greenberg, Edward},
	month = nov,
	year = {1995},
	note = {ArticleType: research-article / Full publication date: Nov., 1995 / Copyright © 1995 American Statistical Association},
	pages = {327--335},
	file = {JSTOR Full Text PDF:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/WFVMJ4FK/Chib and Greenberg - 1995 - Understanding the Metropolis-Hastings Algorithm.pdf:application/pdf}
}

@article{monahan_note_1984,
	title = {A note on enforcing stationarity in autoregressive-moving average models},
	volume = {71},
	issn = {0006-3444, 1464-3510},
	url = {http://biomet.oxfordjournals.org/content/71/2/403},
	doi = {10.1093/biomet/71.2.403},
	abstract = {A simple reparameterization is given that can implicitly restrict the autoregressive moving average parameters to the stationary and invertible region.},
	language = {en},
	number = {2},
	urldate = {2013-11-13},
	journal = {Biometrika},
	author = {Monahan, John F.},
	month = aug,
	year = {1984},
	pages = {403--404},
	file = {Monahan - 1984 - A note on enforcing stationarity in autoregressive.pdf:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/4736SXIG/Monahan - 1984 - A note on enforcing stationarity in autoregressive.pdf:application/pdf;Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/XJIJTH7H/403.html:text/html}
}

@article{durbin_simple_2002,
	title = {A simple and efficient simulation smoother for state space time series analysis},
	volume = {89},
	issn = {0006-3444, 1464-3510},
	url = {http://biomet.oxfordjournals.org/content/89/3/603},
	doi = {10.1093/biomet/89.3.603},
	abstract = {A simulation smoother in state space time series analysis is a procedure for drawing samples from the conditional distribution of state or disturbance vectors given the observations. We present a new technique for this which is both simple and computationally efficient. The treatment includes models with diffuse initial conditions and regression effects. Computational comparisons are made with the previous standard method. Two applications are provided to illustrate the use of the simulation smoother for Gibbs sampling for Bayesian inference and importance sampling for classical inference.},
	language = {en},
	number = {3},
	urldate = {2014-02-07},
	journal = {Biometrika},
	author = {Durbin, J. and Koopman, S. J.},
	month = aug,
	year = {2002},
	pages = {603--616},
	file = {Full Text PDF:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/GUTSQ8FK/Durbin and Koopman - 2002 - A simple and efficient simulation smoother for sta.pdf:application/pdf;Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/U9FDMI3E/603.html:text/html}
}

@article{carter_gibbs_1994,
	title = {On {Gibbs} sampling for state space models},
	volume = {81},
	issn = {0006-3444, 1464-3510},
	url = {http://biomet.oxfordjournals.org/content/81/3/541},
	doi = {10.1093/biomet/81.3.541},
	abstract = {SUMMARY We show how to use the Gibbs sampler to carry out Bayesian inference on a linear state space model with errors that are a mixture of normals and coefficients that can switch over time. Our approach simultaneously generates the whole of the state vector given the mixture and coefficient indicator variables and simultaneously generates all the indicator variables conditional on the state vectors. The states are generated efficiently using the Kalman filter. We illustrate our approach by several examples and empirically compare its performance to another Gibbs sampler where the states are generated one at a time. The empirical results suggest that our approach is both practical to implement and dominates the Gibbs sampler that generates the states one at a time.},
	language = {en},
	number = {3},
	urldate = {2014-02-07},
	journal = {Biometrika},
	author = {Carter, C. K. and Kohn, R.},
	month = sep,
	year = {1994},
	pages = {541--553},
	file = {Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/2THQG844/541.html:text/html}
}

@book{durbin_time_2012,
	title = {Time {Series} {Analysis} by {State} {Space} {Methods}: {Second} {Edition}},
	isbn = {9780199641178},
	shorttitle = {Time {Series} {Analysis} by {State} {Space} {Methods}},
	abstract = {This new edition updates Durbin \& Koopman's important text on the state space approach to time series analysis. The distinguishing feature of state space time series models is that observations are regarded as made up of distinct components such as trend, seasonal, regression elements and disturbance terms, each of which is modelled separately. The techniques that emerge from this approach are very flexible and are capable of handling a much wider range of problems than the main analytical system currently in use for time series analysis, the Box-Jenkins ARIMA system. Additions to this second edition include the filtering of nonlinear and non-Gaussian series. Part I of the book obtains the mean and variance of the state, of a variable intended to measure the effect of an interaction and of regression coefficients, in terms of the observations. Part II extends the treatment to nonlinear and non-normal models. For these, analytical solutions are not available so methods are based on simulation.},
	language = {en},
	publisher = {Oxford University Press},
	author = {Durbin, James and Koopman, Siem Jan},
	month = may,
	year = {2012}
}

@book{hamilton_time_1994,
	title = {Time {Series} {Analysis}},
	isbn = {9780691042893},
	abstract = {The last decade has brought dramatic changes in the way that researchers analyze time series data. This much-needed book synthesizes all of the major recent advances and develops a single, coherent presentation of the current state of the art of this increasingly important field. James Hamilton provides for the first time a thorough and detailed textbook account of important innovations such as vector autoregressions, estimation by generalized method of moments, the economic and statistical consequences of unit roots, time-varying variances, and nonlinear time series models. In addition, Hamilton presents traditional tools for analyzing dynamic systems, including linear representations, autocovariance, generating functions, spectral analysis, and the Kalman filter, illustrating their usefulness both for economic theory and for studying and interpreting real-world data. This book is intended to provide students, researchers, and forecasters with a definitive, self-contained survey of dynamic systems, econometrics, and time series analysis. Starting from first principles, Hamilton's lucid presentation makes both old and new developments accessible to first-year graduate students and nonspecialists. Moreover, the work's thoroughness and depth of coverage will make Time Series Analysis an invaluable reference for researchers at the frontiers of the field. Hamilton achieves these dual objectives by including numerous examples that illustrate exactly how the theoretical results are used and applied in practice, while relegating many details to mathematical appendixes at the end of chapters. As an intellectual roadmap of the field for students and researchers alike, this volume promises to bethe authoritative guide for years to come.},
	language = {en},
	publisher = {Princeton University Press},
	author = {Hamilton, James Douglas},
	month = jan,
	year = {1994}
}

@book{dejong_structural_2011,
	title = {Structural {Macroeconometrics}: ({Second} {Edition})},
	isbn = {1400840503},
	shorttitle = {Structural {Macroeconometrics}},
	abstract = {Structural Macroeconometrics provides a thorough overview and in-depth exploration of methodologies, models, and techniques used to analyze forces shaping national economies. In this thoroughly revised second edition, David DeJong and Chetan Dave emphasize time series econometrics and unite theoretical and empirical research, while taking into account important new advances in the field.  The authors detail strategies for solving dynamic structural models and present the full range of methods for characterizing and evaluating empirical implications, including calibration exercises, method-of-moment procedures, and likelihood-based procedures, both classical and Bayesian. The authors look at recent strides that have been made to enhance numerical efficiency, consider the expanded applicability of dynamic factor models, and examine the use of alternative assumptions involving learning and rational inattention on the part of decision makers. The treatment of methodologies for obtaining nonlinear model representations has been expanded, and linear and nonlinear model representations are integrated throughout the text. The book offers a rich array of implementation algorithms, sample empirical applications, and supporting computer code.  Structural Macroeconometrics is the ideal textbook for graduate students seeking an introduction to macroeconomics and econometrics, and for advanced students pursuing applied research in macroeconomics. The book's historical perspective, along with its broad presentation of alternative methodologies, makes it an indispensable resource for academics and professionals.},
	language = {en},
	publisher = {Princeton University Press},
	author = {DeJong, David N. and Dave, Chetan},
	month = oct,
	year = {2011}
}

@article{koopman_disturbance_1993,
	title = {Disturbance {Smoother} for {State} {Space} {Models}},
	volume = {80},
	copyright = {Copyright © 1993 Biometrika Trust},
	issn = {0006-3444},
	url = {http://www.jstor.org/stable/2336762},
	doi = {10.2307/2336762},
	abstract = {This paper develops a method to evaluate the smoothed estimator of the disturbance vector in a state space model together with its mean squared error matrix. This disturbance smoother also leads to an efficient smoother for the state vector. Applications include a method to calculate auxiliary residuals for unobserved components time series models and an EM algorithm for estimating covariance parameters in a state space model.},
	number = {1},
	urldate = {2014-11-08},
	journal = {Biometrika},
	author = {Koopman, Siem Jan},
	month = mar,
	year = {1993},
	note = {00205},
	pages = {117--126},
	file = {JSTOR Full Text PDF:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/NN2KDRWX/Koopman - 1993 - Disturbance Smoother for State Space Models.pdf:application/pdf}
}

@article{koopman_filtering_2003,
	title = {Filtering and smoothing of state vector for diffuse state–space models},
	volume = {24},
	issn = {01439782},
	url = {http://search.ebscohost.com/login.aspx?direct=true&db=aph&AN=9184943&site=ehost-live&scope=site},
	abstract = {This paper presents exact recursions for calculating the mean and mean square error matrix of the state vector given the observations for the multi–variate linear Gaussian state–space model in the case where the initial state vector is (partially) diffuse.},
	number = {1},
	urldate = {2015-02-27},
	journal = {Journal of Time Series Analysis},
	author = {Koopman, S.j. and Durbin, J.},
	month = jan,
	year = {2003},
	note = {00089},
	pages = {85--98},
	file = {EBSCO Full Text:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/FKVAJ2GZ/Koopman and Durbin - 2003 - Filtering and smoothing of state vector for diffus.pdf:application/pdf}
}

@article{klein_using_2000,
	title = {Using the generalized {Schur} form to solve a multivariate linear rational expectations model},
	volume = {24},
	issn = {0165-1889},
	url = {http://www.sciencedirect.com/science/article/pii/S0165188999000457},
	doi = {10.1016/S0165-1889(99)00045-7},
	abstract = {In this paper, I show how to use the generalized Schur form to solve a system of linear expectational difference equations (a multivariate linear rational expectations model). The method is simple to understand and to use, and is applicable to a large class of rational expectations models. The only hard part is taken care of by just two standard algorithms, both of which are available as freeware on the Internet as part of LAPACK. Like other matrix decomposition based methods, it is also very fast to execute.},
	number = {10},
	urldate = {2015-04-22},
	journal = {Journal of Economic Dynamics and Control},
	author = {Klein, Paul},
	month = sep,
	year = {2000},
	note = {00746},
	pages = {1405--1423},
	file = {ScienceDirect Full Text PDF:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/Z7ZGFVRQ/Klein - 2000 - Using the generalized Schur form to solve a multiv.pdf:application/pdf;ScienceDirect Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/BUDPA22X/S0165188999000457.html:text/html}
}

@article{blanchard_solution_1980,
	title = {The {Solution} of {Linear} {Difference} {Models} under {Rational} {Expectations}},
	volume = {48},
	copyright = {Copyright © 1980 The Econometric Society},
	issn = {0012-9682},
	url = {http://www.jstor.org/stable/1912186},
	doi = {10.2307/1912186},
	number = {5},
	urldate = {2015-04-22},
	journal = {Econometrica},
	author = {Blanchard, Olivier Jean and Kahn, Charles M.},
	month = jul,
	year = {1980},
	note = {02223},
	pages = {1305--1311},
	file = {JSTOR Full Text PDF:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/2WDSHU7U/Blanchard and Kahn - 1980 - The Solution of Linear Difference Models under Rat.pdf:application/pdf}
}

@article{sims_solving_2002,
	title = {Solving {Linear} {Rational} {Expectations} {Models}},
	volume = {20},
	issn = {0927-7099, 1572-9974},
	url = {http://link.springer.com/article/10.1023/A:1020517101123},
	doi = {10.1023/A:1020517101123},
	abstract = {We describe methods for solving general linear rational expectations models in continuous or discrete timing with or without exogenous variables. The methods are based on matrix eigenvalue decompositions.},
	language = {en},
	number = {1-2},
	urldate = {2015-04-22},
	journal = {Computational Economics},
	author = {Sims, Christopher A.},
	month = oct,
	year = {2002},
	note = {01041},
	pages = {1--20},
	file = {476248.pdf:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/JN63RGXG/476248.pdf:application/pdf;Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/N5D77S39/10.html:text/html;solution.pdf:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/KKBDARG7/solution.pdf:application/pdf}
}

@article{ruge-murcia_methods_2007,
	title = {Methods to estimate dynamic stochastic general equilibrium models},
	volume = {31},
	issn = {0165-1889},
	url = {http://www.sciencedirect.com/science/article/pii/S0165188906001758},
	doi = {10.1016/j.jedc.2006.09.005},
	abstract = {This paper employs the one-sector real business cycle model as a testing ground for four different procedures to estimate dynamic stochastic general equilibrium (DSGE) models. The procedures are: (1) maximum likelihood, with and without measurement errors and incorporating priors, (2) generalized method of moments, (3) simulated method of moments, and (4) indirect inference. Monte carlo analysis is used to study the small-sample properties of these estimators and to examine the implications of misspecification, stochastic singularity, and weak identification.},
	number = {8},
	urldate = {2015-04-29},
	journal = {Journal of Economic Dynamics and Control},
	author = {Ruge-Murcia, Francisco J.},
	month = aug,
	year = {2007},
	note = {00163},
	pages = {2599--2636},
	file = {ScienceDirect Full Text PDF:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/6N2PWP5U/Ruge-Murcia - 2007 - Methods to estimate dynamic stochastic general equ.pdf:application/pdf;ScienceDirect Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/2U2CHEQB/S0165188906001758.html:text/html}
}

@article{jungbacker_likelihood-based_2014,
	title = {Likelihood-based dynamic factor analysis for measurement and forecasting},
	copyright = {© 2014 Royal Economic Society.},
	issn = {1368-423X},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/ectj.12029/abstract},
	doi = {10.1111/ectj.12029},
	abstract = {We present new results for the likelihood-based analysis of the dynamic factor model. The latent factors are modelled by linear dynamic stochastic processes. The idiosyncratic disturbance series are specified as autoregressive processes with mutually correlated innovations. The new results lead to computationally efficient procedures for the estimation of the factors and for the parameter estimation by maximum likelihood methods. We also present the implications of our results for models with regression effects, for Bayesian analysis, for signal extraction, and for forecasting. An empirical illustration is provided for the analysis of a large panel of macroeconomic time series.},
	language = {en},
	urldate = {2015-05-13},
	journal = {The Econometrics Journal},
	author = {Jungbacker, Borus and Koopman, Siem Jan},
	month = jun,
	year = {2014},
	note = {00005},
	pages = {n/a--n/a},
	file = {Full Text PDF:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/UWDKH5SC/Jungbacker and Koopman - 2014 - Likelihood-based dynamic factor analysis for measu.pdf:application/pdf;Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/966FFS3N/abstract.html:text/html}
}

@article{commandeur_statistical_2011,
	title = {Statistical {Software} for {State} {Space} {Methods}},
	volume = {41},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v41/i01},
	number = {1},
	journal = {Journal of Statistical Software},
	author = {Commandeur, Jacques J. F. and Koopman, Siem Jan and Ooms, Marius},
	year = {2011},
	note = {00035},
	pages = {1--18}
}

@article{morf_square-root_1975,
	title = {Square-root algorithms for least-squares estimation},
	volume = {20},
	issn = {0018-9286},
	doi = {10.1109/TAC.1975.1100994},
	abstract = {We present several new algorithms, and more generally a new approach, to recursive estimation algorithms for linear dynamical systems. Earlier results in this area have been obtained by several others, especially Potter, Golub, Dyer and McReynolds, Kaminski, Schmidt, Bryson, and Bierman on what are known as square-root algorithms. Our results are more comprehensive. They also show bow constancy of parameters can be exploited to reduce the number of computations and to obtain new forms of the Chandrasekhar-type equations for computing the filter gain. Our approach is essentially based on certain simple geometric interpretations of the overall estimation problem. One of our goals is to attract attention to non-Riccati-based studies of estimation problems.},
	number = {4},
	journal = {IEEE Transactions on Automatic Control},
	author = {Morf, M. and Kailath, T.},
	month = aug,
	year = {1975},
	note = {00215},
	pages = {487--497},
	file = {IEEE Xplore Abstract Record:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/NNE6TT9R/login.html:text/html}
}

@book{anderson_lapack_1999,
	address = {Philadelphia, PA},
	edition = {Third},
	title = {{LAPACK} {Users}' {Guide}},
	isbn = {0-89871-447-8 (paperback)},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Anderson, E. and Bai, Z. and Bischof, C. and Blackford, S. and Demmel, J. and Dongarra, J. and Du Croz, J. and Greenbaum, A. and Hammarling, S. and McKenney, A. and Sorensen, D.},
	year = {1999},
	note = {06283}
}

@article{wegner_concepts_1990,
	title = {Concepts and {Paradigms} of {Object}-oriented {Programming}},
	volume = {1},
	issn = {1055-6400},
	url = {http://doi.acm.org/10.1145/382192.383004},
	doi = {10.1145/382192.383004},
	abstract = {We address the following questions for object-oriented programming:What is it?What are its goals?What are its origins?What are its paradigms?What are its design alternatives?What are its models of concurrency?What are its formal computational models?What comes after object-oriented programming?Starting from software engineering goals, we examine the origins and paradigms of object-oriented programming, explore its language design alternatives, consider its models of concurrency, and review its mathematical models to make them accessible to nonmathematical readers. Finally, we briefly speculate on what may come after object-oriented programming and conclude that it is a robust component-based modeling paradigm that is both effective and fundamental. This paper expands on the OOPSLA 89 keynote talk.},
	number = {1},
	urldate = {2015-09-03},
	journal = {SIGPLAN OOPS Mess.},
	author = {Wegner, Peter},
	month = aug,
	year = {1990},
	note = {00612},
	pages = {7--87}
}

@article{kalman_new_1960,
	title = {A {New} {Approach} to {Linear} {Filtering} and {Prediction} {Problems}},
	volume = {82},
	issn = {0098-2202},
	url = {http://dx.doi.org/10.1115/1.3662552},
	doi = {10.1115/1.3662552},
	abstract = {The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the “state-transition” method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the co-efficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.},
	number = {1},
	urldate = {2015-09-11},
	journal = {Journal of Basic Engineering},
	author = {Kalman, R. E.},
	month = mar,
	year = {1960},
	note = {20388},
	pages = {35--45}
}

@article{patil_pymc:_2010,
	title = {{PyMC}: {Bayesian} {Stochastic} {Modelling} in {Python}},
	volume = {35},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v35/i04},
	number = {4},
	journal = {Journal of Statistical Software},
	author = {Patil, Anand and Huard, David and Fonnesbeck, Christopher J.},
	year = {2010},
	note = {00192},
	pages = {1--81}
}

@article{strickland_pyssm:_2014,
	title = {{PySSM}: {A} {Python} {Module} for {Bayesian} {Inference} of {Linear} {Gaussian} {State} {Space} {Models}},
	volume = {57},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v57/i06},
	number = {6},
	journal = {Journal of Statistical Software},
	author = {Strickland, Christopher and Burdett, Robert and Mengersen, Kerrie and Denham, Robert},
	year = {2014},
	note = {00002},
	pages = {??--??}
}

@book{grewal_kalman_2014,
	address = {Hoboken, New Jersey},
	edition = {4 edition},
	title = {Kalman {Filtering}: {Theory} and {Practice} with {MATLAB}},
	isbn = {9781118851210},
	shorttitle = {Kalman {Filtering}},
	language = {English},
	publisher = {Wiley-IEEE Press},
	author = {Grewal, Mohinder and Andrews, Angus},
	month = dec,
	year = {2014},
	note = {03436}
}

@article{behnel_cython:_2011,
	title = {Cython: {The} {Best} of {Both} {Worlds}},
	volume = {13},
	issn = {1521-9615},
	shorttitle = {Cython},
	url = {http://scitation.aip.org/content/aip/journal/cise/13/2/10.1109/MCSE.2010.118},
	doi = {10.1109/MCSE.2010.118},
	abstract = {Cython is a Python language extension that allows explicit type declarations and is compiled directly to C. As such, it addresses Python\&apos;s large overhead for numerical loops and the difficulty of efficiently using existing C and Fortran code, which Cython can interact with natively.},
	number = {2},
	urldate = {2015-09-12},
	journal = {Computing in Science \& Engineering},
	author = {Behnel, Stefan and Bradshaw, Robert and Citro, Craig and Dalcin, Lisandro and Seljebotn, Dag Sverre and Smith, Kurt},
	month = mar,
	year = {2011},
	note = {00161},
	pages = {31--39},
	file = {Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/HIAK5JEQ/MCSE.2010.html:text/html}
}

@article{mccullough_numerical_1999,
	title = {The {Numerical} {Reliability} of {Econometric} {Software}},
	volume = {37},
	copyright = {Copyright © 1999 American Economic Association},
	issn = {0022-0515},
	url = {http://www.jstor.org/stable/2565215},
	number = {2},
	urldate = {2015-09-12},
	journal = {Journal of Economic Literature},
	author = {McCullough, B. D. and Vinod, H. D.},
	month = jun,
	year = {1999},
	note = {00157},
	pages = {633--665},
	file = {JSTOR Full Text PDF:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/T2GZ8Z9A/McCullough and Vinod - 1999 - The Numerical Reliability of Econometric Software.pdf:application/pdf}
}

@inproceedings{seabold_statsmodels:_2010,
	title = {Statsmodels: {Econometric} and {Statistical} {Modeling} with {Python}},
	shorttitle = {Statsmodels},
	url = {http://conference.scipy.org/proceedings/scipy2010/seabold.html},
	urldate = {2015-09-12},
	booktitle = {Proceedings of the 9th {Python} in {Science} {Conference}},
	author = {Seabold, Skipper and Perktold, Josef},
	year = {2010},
	note = {00027},
	pages = {57--61},
	file = {Full Text PDF:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/KPKWB2QF/Seabold and Perktold - 2010 - Statsmodels Econometric and Statistical Modeling .pdf:application/pdf;Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/HTWTJIN9/seabold.html:text/html}
}

@misc{jones_scipy:_2001,
	title = {{SciPy}: {Open} source scientific tools for {Python}},
	shorttitle = {{SciPy}},
	url = {http://www.scipy.org},
	urldate = {2015-09-12},
	author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu},
	year = {2001},
	note = {00028}
}

@article{canova_back_2009,
	title = {Back to square one: {Identification} issues in {DSGE} models},
	volume = {56},
	issn = {0304-3932},
	shorttitle = {Back to square one},
	url = {http://www.sciencedirect.com/science/article/pii/S0304393209000439},
	doi = {10.1016/j.jmoneco.2009.03.014},
	abstract = {We investigate identification issues in DSGE models and their consequences for parameter estimation and model evaluation when the objective function measures the distance between estimated and model-based impulse responses. Observational equivalence, partial and weak identification problems are widespread and typically produced by an ill-behaved mapping between the structural parameters and the coefficients of the solution. Different objective functions affect identification and small samples interact with parameters identification. Diagnostics to detect identification deficiencies are provided and applied to a widely used model.},
	number = {4},
	urldate = {2015-09-13},
	journal = {Journal of Monetary Economics},
	author = {Canova, Fabio and Sala, Luca},
	month = may,
	year = {2009},
	note = {00406},
	pages = {431--449},
	file = {ScienceDirect Full Text PDF:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/VAPB6GFG/Canova and Sala - 2009 - Back to square one Identification issues in DSGE .pdf:application/pdf;ScienceDirect Snapshot:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/BDD2MPU3/S0304393209000439.html:text/html}
}

@book{koop_bayesian_2003,
	address = {Chichester ; Hoboken, N.J},
	edition = {1 edition},
	title = {Bayesian {Econometrics}},
	isbn = {9780470845677},
	language = {English},
	publisher = {Wiley-Interscience},
	author = {Koop, Gary},
	month = jul,
	year = {2003},
	note = {00006}
}

@book{west_bayesian_1999,
	address = {New York},
	edition = {2nd edition},
	title = {Bayesian {Forecasting} and {Dynamic} {Models}},
	isbn = {9780387947259},
	language = {English},
	publisher = {Springer},
	author = {West, Mike and Harrison, Jeff},
	month = mar,
	year = {1999},
	note = {00000}
}

@article{tierney_markov_1994,
	title = {Markov {Chains} for {Exploring} {Posterior} {Distributions}},
	volume = {22},
	copyright = {Copyright © 1994 Institute of Mathematical Statistics},
	issn = {0090-5364},
	url = {http://www.jstor.org/stable/2242477},
	abstract = {Several Markov chain methods are available for sampling from a posterior distribution. Two important examples are the Gibbs sampler and the Metropolis algorithm. In addition, several strategies are available for constructing hybrid algorithms. This paper outlines some of the basic methods and strategies and discusses some related theoretical and practical issues. On the theoretical side, results from the theory of general state space Markov chains can be used to obtain convergence rates, laws of large numbers and central limit theorems for estimates obtained from Markov chain methods. These theoretical results can be used to guide the construction of more efficient algorithms. For the practical use of Markov chain methods, standard simulation methodology provides several variance reduction techniques and also give guidance on the choice of sample size and allocation.},
	number = {4},
	urldate = {2015-09-14},
	journal = {The Annals of Statistics},
	author = {Tierney, Luke},
	month = dec,
	year = {1994},
	note = {03496},
	pages = {1701--1728},
	file = {JSTOR Full Text PDF:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/D468DGUG/Tierney - 1994 - Markov Chains for Exploring Posterior Distribution.pdf:application/pdf}
}

@article{smets_shocks_2007,
	title = {Shocks and {Frictions} in {US} {Business} {Cycles}: {A} {Bayesian} {DSGE} {Approach}},
	volume = {97},
	copyright = {Copyright © 2007 American Economic Association},
	issn = {0002-8282},
	shorttitle = {Shocks and {Frictions} in {US} {Business} {Cycles}},
	url = {http://www.jstor.org/stable/30035013},
	abstract = {Using a Bayesian likelihood approach, we estimate a dynamic stochastic general equilibrium model for the US economy using seven macroeconomic time series. The model incorporates many types of real and nominal frictions and seven types of structural shocks. We show that this model is able to compete with Bayesian Vector Autoregression models in out-of-sample prediction. We investigate the relative empirical importance of the various frictions. Finally, using the estimated model, we address a number of key issues in business cycle analysis: What are the sources of business cycle fluctuations? Can the model explain the cross correlation between output and inflation? What are the effects of productivity on hours worked? What are the sources of the "Great Moderation"?},
	number = {3},
	urldate = {2015-09-17},
	journal = {The American Economic Review},
	author = {Smets, Frank and Wouters, Rafael},
	month = jun,
	year = {2007},
	note = {02620},
	pages = {586--606},
	file = {JSTOR Full Text PDF:/Users/fulton/Library/Application Support/Zotero/Profiles/q53wy2p5.default/zotero/storage/D7I8HN2C/Smets and Wouters - 2007 - Shocks and Frictions in US Business Cycles A Baye.pdf:application/pdf}
}

@article{mendelssohn_stamp_2011,
	title = {The {STAMP} {Software} for {State} {Space} {Models}},
	volume = {41},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v41/i02},
	number = {2},
	journal = {Journal of Statistical Software},
	author = {Mendelssohn, Roy},
	year = {2011},
	note = {00007},
	pages = {1--18}
}